Timer unit: 1e-09 s

Total time: 0.007521 s
File: /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py
Function: constraints_USHD at line 69

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    69                                           @profile
    70                                           def constraints_USHD(
    71                                               s_cause: np.ndarray,
    72                                               I: int,
    73                                               J: int,
    74                                               K: int,
    75                                               rtol: float = 1e-05, 
    76                                               atol:float = 1e-08
    77                                           ) -> tuple[np.ndarray, np.ndarray]:
    78                                               """Compute the constraints matrix A and the margins vector s for the USHD use case.
    79                                                   
    80                                               This will define the raking optimization problem:
    81                                                   min_beta f(beta,y) s.t. A beta = s
    82                                               The input margins are the 1 + I values:
    83                                                   - beta_000 = Total number of deaths (all causes, all races, at the state level)
    84                                                   - beta_i00 = Number of deaths for cause i (all races, at the state level)
    85                                           
    86                                               Parameters
    87                                               ----------
    88                                               s_cause : np.ndarray
    89                                                   Total number of deaths (all causes, and each cause)
    90                                               I : int
    91                                                   Number of causes of deaths
    92                                               J : int
    93                                                   Number of races and ethnicities
    94                                               K : int
    95                                                   Number of counties
    96                                               rtol : float
    97                                                   Relative tolerance to check whether the margins are consistant. See numpy.allclose documentation for details.
    98                                               atol : float
    99                                                   Absolute tolerance to check whether the margins are consistant. See numpy.allclose documentation for details.
   100                                           
   101                                               Returns
   102                                               -------
   103                                               A : np.ndarray
   104                                                   (I + 2 * K + J * K + (I - 1) * K) * ((I + 1) * (J + 1) * K) constraints matrix
   105                                               s : np.ndarray
   106                                                   length (I + 2 * K + J * K + (I - 1) * K) margins vector
   107                                               """
   108         1       2000.0   2000.0      0.0      assert isinstance(I, int), \
   109                                                   'The number of causes of deaths must be an integer.'
   110         1          0.0      0.0      0.0      assert I > 1, \
   111                                                   'The number of causes of deaths must be higher than 1.'
   112         1          0.0      0.0      0.0      assert isinstance(J, int), \
   113                                                   'The number of races and ethnicities must be an integer.'
   114         1          0.0      0.0      0.0      assert J > 1, \
   115                                                   'The number of races and ethnicities must be higher than 1.'
   116         1          0.0      0.0      0.0      assert isinstance(K, int), \
   117                                                   'The number of counties must be an integer.'
   118         1          0.0      0.0      0.0      assert K > 1, \
   119                                                   'The number of counties must be higher than 1.'
   120                                           
   121         1          0.0      0.0      0.0      assert isinstance(s_cause, np.ndarray), \
   122                                                   'The margins vector for the causes of death must be a Numpy array.'
   123         1       3000.0   3000.0      0.0      assert len(s_cause.shape) == 1, \
   124                                                   'The margins vector for the causes of death must be a 1D Numpy array.'
   125         1      51000.0  51000.0      0.7      assert np.all(s_cause >= 0.0), \
   126                                                   'The number of deaths for each cause must be positive or null.'
   127         1       1000.0   1000.0      0.0      assert len(s_cause) == I + 1, \
   128                                                   'The length of the margins vector for the causes of death must be equal to 1 + number of causes.'
   129                                               
   130         1     216000.0 216000.0      2.9      assert np.allclose(s_cause[0], np.sum(s_cause[1:]), rtol, atol), \
   131                                                   'The all-causes number of deaths must be equal to the sum of the numbers of deaths per cause.'
   132                                           
   133         1      12000.0  12000.0      0.2      A = np.zeros((I + 2 * K + J * K + (I - 1) * K, (I + 1) * (J + 1) * K))
   134         1       2000.0   2000.0      0.0      s = np.zeros(I + 2 * K + J * K + (I - 1) * K)
   135                                               # Constraint sum_k=0,...,K-1 beta_i,0,k = s_i for i=1,...,I
   136         4       1000.0    250.0      0.0      for i in range(0, I):
   137       423      71000.0    167.8      0.9          for k in range(0, K):
   138       420     174000.0    414.3      2.3              A[i, k * (I + 1) * (J + 1) + i + 1] = 1
   139         3       3000.0   1000.0      0.0          s[i] = s_cause[i + 1]
   140                                               # Constraint sum_i=1,...,I beta_i,0,k - beta_0,0,k = 0 for k=0,...,K-1
   141       141      19000.0    134.8      0.3      for k in range(0, K):
   142       560     127000.0    226.8      1.7          for i in range(1, I + 1):
   143       420     609000.0   1450.0      8.1              A[I + k, k * (I + 1) * (J + 1) + i] = 1
   144       140      49000.0    350.0      0.7          A[I + k, k * (I + 1) * (J + 1)] = -1
   145                                               # Constraint sum_j=1,...,J beta_0,j,k - beta_0,0,k = 0 for k=0,...,K-1
   146       141      16000.0    113.5      0.2      for k in range(0, K):
   147       840     145000.0    172.6      1.9          for j in range(1, J + 1):
   148       700     672000.0    960.0      8.9              A[I + K + k, k * (I + 1) * (J + 1) + j * (I + 1)] = 1
   149       140      55000.0    392.9      0.7          A[I + K + k, k * (I + 1) * (J + 1)] = -1
   150                                               # Constraint sum_i=1,...,I beta_i,j,k - beta_0,j,k = 0 for j=1,...,J and k=0,...,K-1
   151       141      17000.0    120.6      0.2      for k in range(0, K):
   152       840     153000.0    182.1      2.0          for j in range(1, J + 1):
   153      2800     554000.0    197.9      7.4              for i in range(1, I + 1):
   154      2100    2591000.0   1233.8     34.5                  A[I + 2 * K + k * J + j - 1, k * (I + 1) * (J + 1) + j * (I + 1) + i] = 1
   155       700     301000.0    430.0      4.0              A[I + 2 * K + k * J + j - 1, k * (I + 1) * (J + 1) + j * (I + 1)] = -1
   156                                               # Constraint sum_j=1,...,J beta_i,j,k - beta_i,0,k = 0 for i=1,...,I and k=0,...,K-1
   157       141      22000.0    156.0      0.3      for k in range(0, K):
   158       420     103000.0    245.2      1.4          for i in range(1, I):
   159      1680     319000.0    189.9      4.2              for j in range(1, J + 1):
   160      1400    1111000.0    793.6     14.8                  A[I + 2 * K + J * K + k * (I - 1) + i - 1, k * (I + 1) * (J + 1) + j * (I + 1) + i] = 1
   161       280     122000.0    435.7      1.6              A[I + 2 * K + J * K + k * (I - 1) + i - 1, k * (I + 1) * (J + 1) + i] = -1
   162                                               return (A, s)

Total time: 0.091136 s
File: /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py
Function: raking_chi2 at line 164

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   164                                           @profile
   165                                           def raking_chi2(
   166                                               y: np.ndarray,
   167                                               A: np.ndarray,
   168                                               s: np.ndarray,
   169                                               q: np.ndarray = None,
   170                                           ) -> tuple[np.ndarray, np.ndarray]:
   171                                               """Raking using the chi2 distance f(beta, y) = (beta - y)^2 / 2y.
   172                                           
   173                                               This will solve the problem:
   174                                                   min_beta 1/q f(beta, y) s.t. A beta = s
   175                                           
   176                                               Parameters
   177                                               ----------
   178                                               y : np.ndarray
   179                                                   Vector of observations
   180                                               A : np.ndarray
   181                                                   Constraints matrix (output of a function from the compute_constraints module)
   182                                               s : np.ndarray
   183                                                   Margin vector (output of a function from the compute_constraints module)
   184                                               q : np.ndarray
   185                                                   Vector of weights (default to all 1)
   186                                           
   187                                               Returns
   188                                               -------
   189                                               beta : np.ndarray
   190                                                   Vector of raked values
   191                                               lambda_k : np.ndarray
   192                                                   Dual (needed for the uncertainty computation)
   193                                               """
   194         1       1000.0   1000.0      0.0      assert isinstance(y, np.ndarray), \
   195                                                   'The vector of observations should be a Numpy array.'
   196         1       1000.0   1000.0      0.0      assert len(y.shape) == 1, \
   197                                                   'The vector of observations should be a 1D Numpy array.'
   198         1       1000.0   1000.0      0.0      if q is not None:
   199                                                   assert isinstance(q, np.ndarray), \
   200                                                       'The vector of weights should be a Numpy array.'
   201                                                   assert len(y.shape) == 1, \
   202                                                       'The vector of weights should be a 1D Numpy array.'
   203                                                   assert len(y) == len(q), \
   204                                                       'Observations and weights vectors should have the same length.'
   205         1          0.0      0.0      0.0      assert isinstance(A, np.ndarray), \
   206                                                   'The constraint matrix should be a Numpy array.'
   207         1       1000.0   1000.0      0.0      assert len(A.shape) == 2, \
   208                                                   'The constraints matrix should be a 2D Numpy array.'
   209         1          0.0      0.0      0.0      assert isinstance(s, np.ndarray), \
   210                                                   'The margins vector should be a Numpy array.'
   211         1       1000.0   1000.0      0.0      assert len(s.shape) == 1, \
   212                                                   'The margins vector should be a 1D Numpy array.'
   213         1       7000.0   7000.0      0.0      assert np.shape(A)[0] == len(s), \
   214                                                   'The number of linear constraints should be equal to the number of margins.'
   215         1       1000.0   1000.0      0.0      assert np.shape(A)[1] == len(y), \
   216                                                   'The number of coefficients for the linear constraints should be equal to the number of observations.'
   217                                           
   218         1          0.0      0.0      0.0      if q is None:
   219         1      13000.0  13000.0      0.0          q = np.ones(len(y))
   220         1    3126000.0    3e+06      3.4      s_hat = np.matmul(A, y)
   221         1   80000000.0    8e+07     87.8      Phi = np.matmul(A, np.transpose(A * y * q))
   222         1    7089000.0    7e+06      7.8      lambda_k = cg(Phi, s_hat - s)[0]
   223         1     895000.0 895000.0      1.0      beta = y * (1 - q * np.matmul(np.transpose(A), lambda_k))
   224                                               return (beta, lambda_k)

Total time: 0.860751 s
File: /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py
Function: raking_entropic at line 226

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   226                                           @profile
   227                                           def raking_entropic(
   228                                               y: np.ndarray,
   229                                               A: np.ndarray,
   230                                               s: np.ndarray,
   231                                               q: np.ndarray = None,
   232                                               gamma0: float = 1.0,
   233                                               max_iter: int = 500
   234                                           ) -> tuple[np.ndarray, np.ndarray, int]:
   235                                               """Raking using the entropic distance f(beta, y) = beta log(beta/y) + y - beta.
   236                                           
   237                                               This will solve the problem:
   238                                                   min_beta 1/q f(beta, y) s.t. A beta = s
   239                                           
   240                                               Parameters
   241                                               ----------
   242                                               y : np.ndarray
   243                                                   Vector of observations
   244                                               A : np.ndarray
   245                                                   Constraints matrix (output of a function from the compute_constraints module)
   246                                               s : np.ndarray
   247                                                   Margin vector (output of a function from the compute_constraints module)
   248                                               q : np.ndarray
   249                                                   Vector of weights (default to all 1)
   250                                               gamma0 : float
   251                                                   Initial value for line search
   252                                               max_iter : int
   253                                                   Number of iterations for Newton's root finding method
   254                                           
   255                                               Returns
   256                                               -------
   257                                               beta : np.ndarray
   258                                                   Vector of reaked values
   259                                               lambda_k : np.ndarray
   260                                                   Dual (needed for th uncertainty computation)
   261                                               iters_eps : int
   262                                                   Number of iterations until convergence
   263                                               """
   264         1       5000.0   5000.0      0.0      assert isinstance(y, np.ndarray), \
   265                                                   'The vector of observations should be a Numpy array.'
   266         1       2000.0   2000.0      0.0      assert len(y.shape) == 1, \
   267                                                   'The vector of observations should be a 1D Numpy array.'
   268         1          0.0      0.0      0.0      if q is not None:
   269                                                   assert isinstance(q, np.ndarray), \
   270                                                       'The vector of weights should be a Numpy array.'
   271                                                   assert len(q.shape) == 1, \
   272                                                       'The vector of weights should be a 1D Numpy array.'
   273                                                   assert len(y) == len(q), \
   274                                                       'Observations and weights vectors should have the same length.'
   275         1       1000.0   1000.0      0.0      assert isinstance(A, np.ndarray), \
   276                                                   'The constraint matrix should be a Numpy array.'
   277         1          0.0      0.0      0.0      assert len(A.shape) == 2, \
   278                                                   'The constraints matrix should be a 2D Numpy array.'
   279         1          0.0      0.0      0.0      assert isinstance(s, np.ndarray), \
   280                                                   'The margins vector should be a Numpy array.'
   281         1       1000.0   1000.0      0.0      assert len(s.shape) == 1, \
   282                                                   'The margins vector should be a 1D Numpy array.'
   283         1       5000.0   5000.0      0.0      assert np.shape(A)[0] == len(s), \
   284                                                   'The number of linear constraints should be equal to the number of margins.'
   285         1       1000.0   1000.0      0.0      assert np.shape(A)[1] == len(y), \
   286                                                   'The number of coefficients for the linear constraints should be equal to the number of observations.'
   287                                           
   288         1          0.0      0.0      0.0      if q is None:
   289         1      26000.0  26000.0      0.0          q = np.ones(len(y))
   290         1     932000.0 932000.0      0.1      s_hat = np.matmul(A, y)
   291         1       6000.0   6000.0      0.0      lambda_k = np.zeros(A.shape[0])
   292         1       9000.0   9000.0      0.0      beta = np.copy(y)
   293         1          0.0      0.0      0.0      epsilon = 1.0
   294         1          0.0      0.0      0.0      iter_eps = 0
   295         4      18000.0   4500.0      0.0      while (epsilon > 1.0e-10) & (iter_eps < max_iter):
   296         3    4029000.0    1e+06      0.5          Phi = np.matmul(A, y * (1.0 - np.exp(- q * np.matmul(np.transpose(A), lambda_k))))
   297         3   25952000.0    9e+06      3.0          D = np.diag(y * q * np.exp(- q * np.matmul(np.transpose(A), lambda_k)))
   298         3  792038000.0    3e+08     92.0          J = np.matmul(np.matmul(A, D), np.transpose(A))
   299         3   31092000.0    1e+07      3.6          delta_lambda = cg(J, Phi - s_hat + s)[0]
   300         3       2000.0    666.7      0.0          gamma = gamma0
   301         3          0.0      0.0      0.0          iter_gam = 0
   302         3      25000.0   8333.3      0.0          lambda_k = lambda_k - gamma * delta_lambda
   303         3    4028000.0    1e+06      0.5          beta = y * np.exp(- q * np.matmul(np.transpose(A), lambda_k))
   304         3       4000.0   1333.3      0.0          if iter_eps > 0:
   305         4     942000.0 235500.0      0.1              while (np.mean(np.abs(s - np.matmul(A, beta))) > epsilon) & \
   306         2       1000.0    500.0      0.0                    (iter_gam < max_iter):
   307                                                           gamma = gamma / 2.0
   308                                                           iter_gam = iter_gam + 1
   309                                                           lambda_k = lambda_k - gamma * delta_lambda
   310                                                           beta = y * np.exp(- q * np.matmul(np.transpose(A), lambda_k))
   311         3    1631000.0 543666.7      0.2          epsilon = np.mean(np.abs(s - np.matmul(A, beta)))
   312         3       1000.0    333.3      0.0          iter_eps = iter_eps + 1
   313                                               return (beta, lambda_k, iter_eps)

Total time: 4.85216 s
File: /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py
Function: solve_system_spsolve at line 337

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   337                                           @profile
   338                                           def solve_system_spsolve(A, B):
   339                                               """
   340                                               Solve system A X = B with X and B vectors instead of matrices
   341                                               Use spares system linear solver
   342                                               Input:
   343                                                 A: N * N sparse square matrix
   344                                                 B: N * M matrix
   345                                               Output:
   346                                                 X: N * M matrix
   347                                               """
   348         2      17000.0   8500.0      0.0      assert np.shape(A)[0] == np.shape(A)[1], \
   349                                                   'A should be a square matrix'
   350         2       5000.0   2500.0      0.0      assert np.shape(A)[1] == np.shape(B)[0], \
   351                                                   'The numbers of columns in A should be equal to the number of rows in B'
   352         2  200938000.0    1e+08      4.1      A = csc_matrix(A)
   353         2  201051000.0    1e+08      4.1      B = csc_matrix(B)
   354         2 4450150000.0    2e+09     91.7      X = spsolve(A, B)
   355                                               return X

Total time: 70.0496 s
File: /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py
Function: solve_system_lu at line 315

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   315                                           @profile
   316                                           def solve_system_lu(A, B):
   317                                               """
   318                                               Solve system A X = B with X and B vectors instead of matrices
   319                                               Use LU factorization of A
   320                                               Input:
   321                                                 A: N * N sparse square matrix
   322                                                 B: N * M matrix
   323                                               Output:
   324                                                 X: N * M matrix
   325                                               """
   326         2      22000.0  11000.0      0.0      assert np.shape(A)[0] == np.shape(A)[1], \
   327                                                   'A should be a square matrix'
   328         2       3000.0   1500.0      0.0      assert np.shape(A)[1] == np.shape(B)[0], \
   329                                                   'The numbers of columns in A should be equal to the number of rows in B'
   330         2       2000.0   1000.0      0.0      M = np.shape(B)[1]
   331         2   28201000.0    1e+07      0.0      X = np.zeros_like(B)
   332         2  916399000.0    5e+08      1.3      lu, piv = lu_factor(A)
   333      9248    7290000.0    788.3      0.0      for i in range(0, M):
   334      9246        7e+10    7e+06     98.6          X[:, i] = lu_solve((lu, piv), B[:, i])
   335                                               return X

Total time: 75.3636 s
File: /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py
Function: compute_gradient at line 357

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   357                                           @profile
   358                                           def compute_gradient(
   359                                               beta_0: np.ndarray,
   360                                               lambda_0: np.ndarray,
   361                                               y: np.ndarray,
   362                                               A: np.ndarray,
   363                                               method: str,
   364                                               alpha: float = 1,
   365                                               l: np.ndarray = None,
   366                                               h: np.ndarray = None, 
   367                                               q: np.ndarray = None
   368                                           ) -> tuple[np.ndarray, np.ndarray]:
   369                                               """Compute the gradient dbeta/dy and dbeta/ds.
   370                                           
   371                                               The covariance matrix of the raked values is phi' Sigma phi'T
   372                                               where phi' is the matrix of the partial derivatives of the raked values beta
   373                                               with respect to the observations y and margins s. This function computes phi'
   374                                           
   375                                               Parameters
   376                                               ----------
   377                                               beta_0 : np.ndarray
   378                                                   Vector of raked values
   379                                               lambda_0 : np.ndarray
   380                                                   Corresponding dual
   381                                               y : np.ndarray
   382                                                   Vector of observations
   383                                               A : np.ndarray
   384                                                   Constraints matrix (output of a function from the compute_constraints module)
   385                                               method : string
   386                                                   Raking method (one of chi2, entropic, general, logit)
   387                                               alpha : float
   388                                                   Parameter of the distance function, alpha=1 is the chi2 distance, alpha=0 is the entropic distance
   389                                               l : np.ndarray
   390                                                   Lower bounds for the observations
   391                                               h : np.ndarray
   392                                                   Upper bounds for the observations
   393                                               q :  np.ndarray
   394                                                   Vector of weights (default to all 1)
   395                                           
   396                                               Returns
   397                                               -------
   398                                               Dphi_y : np.ndarray
   399                                                   Derivatives with respect to the observations
   400                                               Dphi_s: np.ndarray
   401                                                   Derivatives with respect to the margins
   402                                               """
   403         2      15000.0   7500.0      0.0      assert isinstance(beta_0, np.ndarray), \
   404                                                   'The vector of raked values should be a Numpy array.'
   405         2       1000.0    500.0      0.0      assert len(beta_0.shape) == 1, \
   406                                                   'The vector of raked values should be a 1D Numpy array.'
   407         2          0.0      0.0      0.0      assert isinstance(lambda_0, np.ndarray), \
   408                                                   'The dual vector should be a Numpy array.'
   409         2          0.0      0.0      0.0      assert len(lambda_0.shape) == 1, \
   410                                                   'The vdual vector should be a 1D Numpy array.'
   411         2       1000.0    500.0      0.0      assert isinstance(y, np.ndarray), \
   412                                                   'The vector of observations should be a Numpy array.'
   413         2          0.0      0.0      0.0      assert len(y.shape) == 1, \
   414                                                   'The vector of observations should be a 1D Numpy array.'
   415         2       2000.0   1000.0      0.0      assert len(y) == len(beta_0), \
   416                                                   'The vectors of observations and raked values should have the same length.'
   417         2          0.0      0.0      0.0      assert isinstance(A, np.ndarray), \
   418                                                   'The constraint matrix should be a Numpy array.'
   419         2       1000.0    500.0      0.0      assert len(A.shape) == 2, \
   420                                                   'The constraints matrix should be a 2D Numpy array.'
   421         2       6000.0   3000.0      0.0      assert np.shape(A)[0] == len(lambda_0), \
   422                                                   'The number of linear constraints should be equal to the length of the dual vector.'
   423         2       1000.0    500.0      0.0      assert np.shape(A)[1] == len(y), \
   424                                                   'The number of coefficients for the linear constraints should be equal to the number of observations.'
   425         2       2000.0   1000.0      0.0      assert method in ['chi2', 'entropic', 'general', 'logit'], \
   426                                                   'The raking method must be "chi2", "entropic", "general", or "logit".'
   427         2          0.0      0.0      0.0      if method == 'general':
   428                                                   assert isinstance(alpha, (int, float)), \
   429                                                       'The parameter of the distance function should be an integer or a float.'
   430         2          0.0      0.0      0.0      if method == 'logit':
   431                                                   if l is None:
   432                                                       l = np.zeros(len(y))
   433                                                   assert isinstance(l, np.ndarray), \
   434                                                       'The vector of lower bounds should be a Numpy array.'
   435                                                   assert len(l.shape) == 1, \
   436                                                       'The vector of lower bounds should be a 1D Numpy array.'
   437                                                   assert len(y) == len(l), \
   438                                                       'Observations and lower bounds vectors should have the same length.'
   439                                                   assert np.all(l >= 0.0), \
   440                                                       'The lower bounds must be positive.'
   441                                                   assert np.all(l <= y), \
   442                                                       'The observations must be superior or equal to the corresponding lower bounds.'
   443                                                   if h is None:
   444                                                       h = np.ones(len(y))
   445                                                   assert isinstance(h, np.ndarray), \
   446                                                       'The vector of upper bounds should be a Numpy array.'
   447                                                   assert len(h.shape) == 1, \
   448                                                       'The vector of upper bounds should be a 1D Numpy array.'
   449                                                   assert len(y) == len(h), \
   450                                                       'Observations and upper bounds vectors should have the same length.'
   451                                                   assert np.all(h > 0.0), \
   452                                                       'The upper bounds must be strictly positive.'
   453                                                   assert np.all(h >= y), \
   454                                                       'The observations must be inferior or equal to the correspondings upper bounds.'   
   455                                                   assert np.all(l < h), \
   456                                                       'The lower bounds must be stricty inferior to the correspondings upper bounds.'
   457         2       1000.0    500.0      0.0      if q is not None:
   458                                                   assert isinstance(q, np.ndarray), \
   459                                                       'The vector of weights should be a Numpy array.'
   460                                                   assert len(q.shape) == 1, \
   461                                                       'The vector of weights should be a 1D Numpy array.'
   462                                                   assert len(y) == len(q), \
   463                                                       'Observations and weights vectors should have the same length.'
   464                                           
   465         2       1000.0    500.0      0.0      if q is None:
   466         2      20000.0  10000.0      0.0          q = np.ones(len(y))
   467                                           
   468                                               # Partial derivatives of the distance function with respect to raked values and observations
   469         2       1000.0    500.0      0.0      if method == 'chi2':
   470         1       1000.0   1000.0      0.0          DF1_beta_diag = np.zeros(len(beta_0))
   471         1      35000.0  35000.0      0.0          DF1_beta_diag[y!=0] = 1.0 / (q[y!=0] * y[y!=0])
   472         1       4000.0   4000.0      0.0          DF1_beta_diag[y==0] = 0.0
   473         1    3414000.0    3e+06      0.0          DF1_beta = np.diag(DF1_beta_diag)
   474         1       1000.0   1000.0      0.0          DF1_y_diag = np.zeros(len(y))
   475         1      36000.0  36000.0      0.0          DF1_y_diag[y!=0] = - beta_0[y!=0] / (q[y!=0] * np.square(y[y!=0]))
   476         1       2000.0   2000.0      0.0          DF1_y_diag[y==0] = 0.0
   477         1    3278000.0    3e+06      0.0          DF1_y = np.diag(DF1_y_diag)
   478         1          0.0      0.0      0.0      elif method == 'entropic':
   479         1       3000.0   3000.0      0.0          DF1_beta_diag = np.zeros(len(beta_0))
   480         1      34000.0  34000.0      0.0          DF1_beta_diag[beta_0!=0] = 1.0 / (q[beta_0!=0] * beta_0[beta_0!=0])
   481         1       3000.0   3000.0      0.0          DF1_beta_diag[beta_0==0] = 0.0
   482         1    6840000.0    7e+06      0.0          DF1_beta = np.diag(DF1_beta_diag)
   483         1       3000.0   3000.0      0.0          DF1_y_diag = np.zeros(len(y))
   484         1      25000.0  25000.0      0.0          DF1_y_diag[y!=0] = - 1.0 / (q[y!=0] * y[y!=0])
   485         1       3000.0   3000.0      0.0          DF1_y_diag[y==0] = 0.0
   486         1    7510000.0    8e+06      0.0          DF1_y = np.diag(DF1_y_diag)
   487                                               elif method == 'general':
   488                                                   DF1_beta_diag = np.zeros(len(beta_0))
   489                                                   DF1_beta_diag[(y!=0)&(beta_0!=0)] = \
   490                                                       np.power(beta_0[(y!=0)&(beta_0!=0)], alpha - 1.0) / \
   491                                                       (q[(y!=0)&(beta_0!=0)] * np.power(y[(y!=0)&(beta_0!=0)], alpha))
   492                                                   DF1_beta_diag[(y==0)|(beta_0==0)] = 0.0
   493                                                   DF1_beta = np.diag(DF1_beta_diag)
   494                                                   DF1_y_diag = np.zeros(len(y))
   495                                                   DF1_y_diag[(y!=0)&(beta_0!=0)] = \
   496                                                       - np.power(beta_0[(y!=0)&(beta_0!=0)], alpha) / \
   497                                                       (q[(y!=0)&(beta_0!=0)] * np.power(y[(y!=0)&(beta_0!=0)], alpha + 1.0))
   498                                                   DF1_y_diag[(y==0)|(beta_0==0)] = 0.0
   499                                                   DF1_y = np.diag(DF1_y_diag)
   500                                               elif method == 'logit':
   501                                                   DF1_beta_diag = np.zeros(len(beta_0))
   502                                                   DF1_beta_diag[(beta_0!=l)&(beta_0!=h)] = \
   503                                                       1.0 / (beta_0[(beta_0!=l)&(beta_0!=h)] - l[(beta_0!=l)&(beta_0!=h)]) + \
   504                                                       1.0 / (h[(beta_0!=l)&(beta_0!=h)] - beta_0[(beta_0!=l)&(beta_0!=h)])
   505                                                   DF1_beta_diag[(beta_0==l)|(beta_0==h)] = 0.0
   506                                                   DF1_beta = np.diag(DF1_beta_diag)
   507                                                   DF1_y_diag = np.zeros(len(y))
   508                                                   DF1_y_diag[(y!=l)&(y!=h)] = \
   509                                                       - 1.0 / (y[(y!=l)&(y!=h)] - l[(y!=l)&(y!=h)]) - \
   510                                                       1.0 / (h[(y!=l)&(y!=h)] - y[(y!=l)&(y!=h)])
   511                                                   DF1_y_diag[(y==l)|(y==h)] = 0.0
   512                                                   DF1_y = np.diag(DF1_y_diag)
   513                                           
   514                                               # Gradient with respect to beta and lambda
   515         2    5770000.0    3e+06      0.0      DF1_lambda = np.transpose(np.copy(A))
   516         2    5547000.0    3e+06      0.0      DF2_beta = np.copy(A)
   517         2    1120000.0 560000.0      0.0      DF2_lambda = np.zeros((np.shape(A)[0], np.shape(A)[0]))    
   518         6   34525000.0    6e+06      0.0      DF_beta_lambda = np.concatenate(( \
   519         2   32960000.0    2e+07      0.0          np.concatenate((DF1_beta, DF1_lambda), axis=1), \
   520         4    9460000.0    2e+06      0.0          np.concatenate((DF2_beta, DF2_lambda), axis=1)), axis=0)
   521                                           
   522                                               # Gradient with respect to y and s
   523         2    4382000.0    2e+06      0.0      DF1_s = np.zeros((np.shape(A)[1], np.shape(A)[0]))
   524         2    2909000.0    1e+06      0.0      DF2_y = np.zeros((np.shape(A)[0], np.shape(A)[1]))
   525         2    1626000.0 813000.0      0.0      DF2_s = - np.identity(np.shape(A)[0])    
   526         6   32180000.0    5e+06      0.0      DF_y_s = np.concatenate(( \
   527         2   26356000.0    1e+07      0.0          np.concatenate((DF1_y, DF1_s), axis=1), \
   528         4   11779000.0    3e+06      0.0          np.concatenate((DF2_y, DF2_s), axis=1)), axis=0)
   529                                           
   530                                               # LU solver
   531         2        7e+10    4e+10     93.1      Dphi_lu = solve_system_lu(DF_beta_lambda, - DF_y_s)
   532         2      30000.0  15000.0      0.0      Dphi_y_lu = Dphi_lu[0:np.shape(A)[1], 0:np.shape(A)[1]]
   533         2       6000.0   3000.0      0.0      Dphi_s_lu = Dphi_lu[0:np.shape(A)[1], np.shape(A)[1]:(np.shape(A)[0] + np.shape(A)[1])]
   534                                           
   535                                               # Sparse solver
   536         2 4906082000.0    2e+09      6.5      Dphi_sp = solve_system_spsolve(DF_beta_lambda, - DF_y_s)
   537         2   90814000.0    5e+07      0.1      Dphi_y_sp = Dphi_sp[0:np.shape(A)[1], 0:np.shape(A)[1]]
   538         2   38451000.0    2e+07      0.1      Dphi_s_sp = Dphi_sp[0:np.shape(A)[1], np.shape(A)[1]:(np.shape(A)[0] + np.shape(A)[1])]
   539                                           
   540                                               return (Dphi_y_lu, Dphi_s_lu, Dphi_y_sp, Dphi_s_sp)

  0.01 seconds - /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py:69 - constraints_USHD
  0.09 seconds - /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py:164 - raking_chi2
  0.86 seconds - /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py:226 - raking_entropic
  4.85 seconds - /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py:337 - solve_system_spsolve
 70.05 seconds - /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py:315 - solve_system_lu
 75.36 seconds - /Users/ducela/Documents/Raking/ihmeuw-msca/raking/profiling/profile_uncertainty.py:357 - compute_gradient
